{"cells":[{"cell_type":"code","source":["pip install kafka-python"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"519a2bef-7174-42bf-a159-558dc364d6e3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting kafka-python\n  Using cached kafka_python-2.0.2-py2.py3-none-any.whl (246 kB)\nInstalling collected packages: kafka-python\nSuccessfully installed kafka-python-2.0.2\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting kafka-python\n  Using cached kafka_python-2.0.2-py2.py3-none-any.whl (246 kB)\nInstalling collected packages: kafka-python\nSuccessfully installed kafka-python-2.0.2\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["pip install avro"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bc4048d0-ad03-47ef-9508-0446ea2ebedc"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting avro\n  Downloading avro-1.10.1.tar.gz (68 kB)\nBuilding wheels for collected packages: avro\n  Building wheel for avro (setup.py): started\n  Building wheel for avro (setup.py): finished with status &#39;done&#39;\n  Created wheel for avro: filename=avro-1.10.1-py3-none-any.whl size=96804 sha256=a56f6ec6e10a6fec19e4c8fe4b48cc15ae232404ebe515868a27e44e5fa8ea73\n  Stored in directory: /root/.cache/pip/wheels/97/a2/d2/fc16baff96b000ffffd8d359730fa92239279ab34b0dd66104\nSuccessfully built avro\nInstalling collected packages: avro\nSuccessfully installed avro-1.10.1\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting avro\n  Downloading avro-1.10.1.tar.gz (68 kB)\nBuilding wheels for collected packages: avro\n  Building wheel for avro (setup.py): started\n  Building wheel for avro (setup.py): finished with status &#39;done&#39;\n  Created wheel for avro: filename=avro-1.10.1-py3-none-any.whl size=96804 sha256=a56f6ec6e10a6fec19e4c8fe4b48cc15ae232404ebe515868a27e44e5fa8ea73\n  Stored in directory: /root/.cache/pip/wheels/97/a2/d2/fc16baff96b000ffffd8d359730fa92239279ab34b0dd66104\nSuccessfully built avro\nInstalling collected packages: avro\nSuccessfully installed avro-1.10.1\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%scala\nSystem.setProperty(\"ssl.ca.location\",\"dbfs:/FileStore/tables/cloudkarafka.ca\");"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4f745f09-3558-47de-9e4f-fe5a339bb04e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">res0: String = dbfs:/FileStore/tables/cloudkarafka.ca\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">res0: String = dbfs:/FileStore/tables/cloudkarafka.ca\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%scala\nSystem.clearProperty(\"java.security.auth.login.config\");\nSystem.clearProperty(\"sasl.jaas.config\");\nSystem.setProperty(\"java.security.auth.login.config\", \"dbfs:/FileStore/tables/cloudkarafka.jaas\");\nSystem.setProperty(\"sasl.jaas.config\", \"dbfs:/FileStore/tables/cloudkarafka.jaas\");\nprintln(\"auth.lang:\" + System.getProperty(\"java.security.auth.login.config\"));\nprintln(\"sasl.jaas:\" + System.getProperty(\"sasl.jaas.config\"));\n\nspark.sparkContext.addFile(\"dbfs:/FileStore/tables/cloudkarafka.jaas\")\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cd6f7258-387d-47b8-af6c-f5100c50789c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">auth.lang:dbfs:/FileStore/tables/cloudkarafka.jaas\nsasl.jaas:dbfs:/FileStore/tables/cloudkarafka.jaas\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">auth.lang:dbfs:/FileStore/tables/cloudkarafka.jaas\nsasl.jaas:dbfs:/FileStore/tables/cloudkarafka.jaas\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import Row\nfrom pyspark.sql.avro.functions import from_avro, to_avro\n\ntopic = \"yrmfqh3q-avro-input\"\n\nprint(\"====================== Read CSV ======================\")\nfilePath = \"/FileStore/tables/customer_applications.csv\"\nread_csv_df = spark.read.format('csv').options(header='true').options(inferSchema='true').load(filePath)\nprint(\"read_csv_df:\", read_csv_df)\nread_csv_df.show()\n\ndef convertToAVRO(in_df):\n  print(\"convertToAVRO::in_df:\", in_df)\n  in_df.show()\n  return in_df\n\n#easy way\navro_write_loc = \"/tmp/csv2avro\"\nread_csv_df.write.format(\"avro\").mode(\"overwrite\").save(avro_write_loc)\nprint(\"STEP-1:COMPLETED CSV TO AVRO USING DF. NO-TRANSFORMATION\")\n\n#Ideal way:\n#Convert to AVRO\n#avroDf = read_csv_df.transform(convertToAVRO)\n#print(\"avroDf:\", avroDf)\n#avroDf.show()\n#avroDf.count()\n\nprint(\"STEP-2:START READ AVRO AND PUSH TO KAFKA\")\nread_avro_df = spark.read.format('avro').load(avro_write_loc + \"/part*.avro\")\nprint(\"read_avro_df:\", read_avro_df)\nread_avro_df.show()\n\nfrom kafka import KafkaProducer\n\ndef publishToKafka2(rows):\n  print(\"publishToKafka2:\", type(rows), rows)\n  producer = KafkaProducer(\n    bootstrap_servers=['omnibus-01.srvs.cloudkafka.com:9094','omnibus-03.srvs.cloudkafka.com:9094','omnibus-02.srvs.cloudkafka.com:9094'],\n    client_id= \"Kafka-Producer\",\n    security_protocol=\"SASL_SSL\",\n    sasl_mechanism=\"SCRAM-SHA-256\",\n    sasl_plain_username=\"yrmfqh3q\",\n    sasl_plain_password=\"WfKJEYL_hwNUHVU8laSbj6gXkPIw_xuc\")\n  for row in rows:\n    print(\"publishToKafka2::row:\", type(row), row)\n    #producer.send(topic, {\"message\", str(row.asDict())} )\n    print(\"row:\", type(row), row)\n    producer.send(topic, key=b'message', value=bytes(str(row.asDict()), \"utf-8\"))\n  producer.flush() #Flush after queuing up all the rows.\n\nread_avro_df.foreachPartition(publishToKafka2)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d23445b2-b8fd-435b-86e2-a346059e3b24"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">====================== Read CSV ======================\nread_csv_df: DataFrame[id: int, cust_id: int, app_id: int, active: int]\n+---+-------+------+------+\n| id|cust_id|app_id|active|\n+---+-------+------+------+\n|  1|      1|     1|     1|\n|  2|      1|     2|     1|\n|  2|      2|     1|     1|\n|  2|      2|     2|     1|\n|  3|      3|     1|     1|\n|  4|      3|     2|     0|\n+---+-------+------+------+\n\nSTEP-1:COMPLETED CSV TO AVRO USING DF. NO-TRANSFORMATION\nSTEP-2:START READ AVRO AND PUSH TO KAFKA\nread_avro_df: DataFrame[id: int, cust_id: int, app_id: int, active: int]\n+---+-------+------+------+\n| id|cust_id|app_id|active|\n+---+-------+------+------+\n|  1|      1|     1|     1|\n|  2|      1|     2|     1|\n|  2|      2|     1|     1|\n|  2|      2|     2|     1|\n|  3|      3|     1|     1|\n|  4|      3|     2|     0|\n+---+-------+------+------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">====================== Read CSV ======================\nread_csv_df: DataFrame[id: int, cust_id: int, app_id: int, active: int]\n+---+-------+------+------+\n id|cust_id|app_id|active|\n+---+-------+------+------+\n  1|      1|     1|     1|\n  2|      1|     2|     1|\n  2|      2|     1|     1|\n  2|      2|     2|     1|\n  3|      3|     1|     1|\n  4|      3|     2|     0|\n+---+-------+------+------+\n\nSTEP-1:COMPLETED CSV TO AVRO USING DF. NO-TRANSFORMATION\nSTEP-2:START READ AVRO AND PUSH TO KAFKA\nread_avro_df: DataFrame[id: int, cust_id: int, app_id: int, active: int]\n+---+-------+------+------+\n id|cust_id|app_id|active|\n+---+-------+------+------+\n  1|      1|     1|     1|\n  2|      1|     2|     1|\n  2|      2|     1|     1|\n  2|      2|     2|     1|\n  3|      3|     1|     1|\n  4|      3|     2|     0|\n+---+-------+------+------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e48c29b0-7429-47cc-ba7c-72e6662d3b81"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"type":"ipynbError","data":"","errorSummary":"","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"batch-avro-2-kafka","dashboards":[],"language":"python","widgets":{},"notebookOrigID":3217293903452125}},"nbformat":4,"nbformat_minor":0}
