{"cells":[{"cell_type":"code","source":["pip install kafka-python"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"519a2bef-7174-42bf-a159-558dc364d6e3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting kafka-python\n  Using cached kafka_python-2.0.2-py2.py3-none-any.whl (246 kB)\nInstalling collected packages: kafka-python\nSuccessfully installed kafka-python-2.0.2\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting kafka-python\n  Using cached kafka_python-2.0.2-py2.py3-none-any.whl (246 kB)\nInstalling collected packages: kafka-python\nSuccessfully installed kafka-python-2.0.2\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%scala\nSystem.setProperty(\"ssl.ca.location\",\"dbfs:/FileStore/tables/cloudkarafka_apr2021.ca\");"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4f745f09-3558-47de-9e4f-fe5a339bb04e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">res1: String = dbfs:/FileStore/tables/cloudkarafka_apr2021.ca\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">res1: String = dbfs:/FileStore/tables/cloudkarafka_apr2021.ca\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%scala\nSystem.clearProperty(\"java.security.auth.login.config\");\nSystem.clearProperty(\"sasl.jaas.config\");\nSystem.setProperty(\"java.security.auth.login.config\", \"dbfs:/FileStore/tables/cloudkarafka_apr2021.jaas\");\nSystem.setProperty(\"sasl.jaas.config\", \"dbfs:/FileStore/tables/cloudkarafka_apr2021.jaas\");\nprintln(\"auth.lang:\" + System.getProperty(\"java.security.auth.login.config\"));\nprintln(\"sasl.jaas:\" + System.getProperty(\"sasl.jaas.config\"));\n\nspark.sparkContext.addFile(\"dbfs:/FileStore/tables/cloudkarafka_apr2021.jaas\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cd6f7258-387d-47b8-af6c-f5100c50789c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">auth.lang:dbfs:/FileStore/tables/cloudkarafka_apr2021.jaas\nsasl.jaas:dbfs:/FileStore/tables/cloudkarafka_apr2021.jaas\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">auth.lang:dbfs:/FileStore/tables/cloudkarafka_apr2021.jaas\nsasl.jaas:dbfs:/FileStore/tables/cloudkarafka_apr2021.jaas\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["topic = \"1agne3o4-input\"\n\nprint(\"====================== CSV Read ======================\")\nfilePath = \"/FileStore/tables/customer_applications_big.csv\"\nread = spark.read.format('csv').options(header='true').options(inferSchema='true').load(filePath)\nread.show()\n\nfrom kafka import KafkaProducer\n\nprint(\"read-type:\", type(read))\n\ndef publishToKafka2(rows):\n  print(\"publishToKafka2:\", type(rows), rows)\n  producer = KafkaProducer(\n    bootstrap_servers=['omnibus-01.srvs.cloudkafka.com:9094','omnibus-03.srvs.cloudkafka.com:9094','omnibus-02.srvs.cloudkafka.com:9094'],\n    client_id= \"Kafka-Producer\",\n    security_protocol=\"SASL_SSL\",\n    sasl_mechanism=\"SCRAM-SHA-256\",\n    sasl_plain_username=\"1agne3o4\",\n    sasl_plain_password=\"hlifEhEaV6Gk3Fbu9m_cWzlhTezWUof6\")\n  for row in rows:\n    print(\"publishToKafka2::Producing.....row:\", type(row), row)\n    #producer.send(topic, {\"message\", str(row.asDict())} )\n    producer.send(topic, key=b'message', value=bytes(str(row.asDict()), \"utf-8\"))\n    print(\"publishToKafka2::Sent.....row:\", type(row), row)\n  producer.flush() #Flush after queuing up all the rows.\n  print(\"publishToKafka2::Flushed\")\n\nread.foreachPartition(publishToKafka2)\nprint(\"Produced Successfully - ALL DONE\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d23445b2-b8fd-435b-86e2-a346059e3b24"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">====================== CSV Read ======================\n+---+-------+------+------+\n| id|cust_id|app_id|active|\n+---+-------+------+------+\n|  1|      1|     1|     1|\n|  2|      1|     2|     1|\n|  2|      2|     1|     1|\n|  2|      2|     2|     1|\n|  3|      3|     1|     1|\n|  4|      3|     2|     0|\n|  1|      1|     1|     1|\n|  2|      1|     2|     1|\n|  2|      2|     1|     1|\n|  2|      2|     2|     1|\n|  3|      3|     1|     1|\n|  4|      3|     2|     0|\n|  1|      1|     1|     1|\n|  2|      1|     2|     1|\n|  2|      2|     1|     1|\n|  2|      2|     2|     1|\n|  3|      3|     1|     1|\n|  4|      3|     2|     0|\n|  1|      1|     1|     1|\n|  2|      1|     2|     1|\n+---+-------+------+------+\nonly showing top 20 rows\n\nread-type: &lt;class &#39;pyspark.sql.dataframe.DataFrame&#39;&gt;\nProduced Successfully - ALL DONE\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">====================== CSV Read ======================\n+---+-------+------+------+\n id|cust_id|app_id|active|\n+---+-------+------+------+\n  1|      1|     1|     1|\n  2|      1|     2|     1|\n  2|      2|     1|     1|\n  2|      2|     2|     1|\n  3|      3|     1|     1|\n  4|      3|     2|     0|\n  1|      1|     1|     1|\n  2|      1|     2|     1|\n  2|      2|     1|     1|\n  2|      2|     2|     1|\n  3|      3|     1|     1|\n  4|      3|     2|     0|\n  1|      1|     1|     1|\n  2|      1|     2|     1|\n  2|      2|     1|     1|\n  2|      2|     2|     1|\n  3|      3|     1|     1|\n  4|      3|     2|     0|\n  1|      1|     1|     1|\n  2|      1|     2|     1|\n+---+-------+------+------+\nonly showing top 20 rows\n\nread-type: &lt;class &#39;pyspark.sql.dataframe.DataFrame&#39;&gt;\nProduced Successfully - ALL DONE\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":[""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6599ee09-7572-413b-963a-18e47ccf0b49"}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"batch-csv-2-kafka","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":825614097682547}},"nbformat":4,"nbformat_minor":0}
