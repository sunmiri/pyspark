{"cells":[{"cell_type":"code","source":["%scala\nSystem.setProperty(\"ssl.ca.location\",\"dbfs:/FileStore/tables/cloudkarafka.ca\");"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b8c79f5f-730a-4ad9-86fb-fe541b40cb2b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">res1: String = dbfs:/FileStore/tables/cloudkarafka.ca\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">res1: String = dbfs:/FileStore/tables/cloudkarafka.ca\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["#dbutils.fs.rm(\"dbfs:/FileStore/tables/cloudkarafka.jaas\")\ndbutils.fs.head(\"dbfs:/FileStore/tables/cloudkarafka.jaas\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1b2b7fc2-8cd5-4c24-91f4-8af50020d9be"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[1]: &#39;KafkaClient {\\n  org.apache.kafka.common.security.scram.ScramLoginModule required\\n  username=&#34;yrmfqh3q&#34;\\n  password=&#34;WfKJEYL_hwNUHVU8laSbj6gXkPIw_xuc&#34;;\\n};&#39;</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[1]: &#39;KafkaClient {\\n  org.apache.kafka.common.security.scram.ScramLoginModule required\\n  username=&#34;yrmfqh3q&#34;\\n  password=&#34;WfKJEYL_hwNUHVU8laSbj6gXkPIw_xuc&#34;;\\n};&#39;</div>"]}}],"execution_count":0},{"cell_type":"code","source":["dbutils.fs.rm(\"/tmp/stream/pykafka_test/\", True);"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"733ca0d0-ad43-4cd2-b791-69429ba0515c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">UsageError: Line magic function `%fs` not found.\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">UsageError: Line magic function `%fs` not found.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%fs mkdirs /tmp/stream/pykafka_test/"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b7fa75a0-c032-4284-93e9-b6c86880833b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">res3: Boolean = true\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">res3: Boolean = true\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["%scala\nSystem.clearProperty(\"java.security.auth.login.config\");\nSystem.clearProperty(\"sasl.jaas.config\");\nSystem.setProperty(\"java.security.auth.login.config\", \"dbfs:/FileStore/tables/cloudkarafka.jaas\");\nSystem.setProperty(\"sasl.jaas.config\", \"dbfs:/FileStore/tables/cloudkarafka.jaas\");\nprintln(\"auth.lang:\" + System.getProperty(\"java.security.auth.login.config\"));\nprintln(\"sasl.jaas:\" + System.getProperty(\"sasl.jaas.config\"));\n\n//spark.conf.set(\"spark.driver.extraJavaOptions\", \"-Djava.security.auth.login.config=/FileStore/tables/cloudkarafka.jaas\")\n//spark.conf.set(\"spark.executor.extraJavaOptions\", \"-Djava.security.auth.login.config=/FileStore/tables/cloudkarafka.jaas\")\nspark.sparkContext.addFile(\"dbfs:/FileStore/tables/kafka_clients_2_4_1.jar\")\nspark.sparkContext.addFile(\"dbfs:/FileStore/tables/spark_streaming_kafka_0_10_2_12_3_0_1.jar\")\nspark.sparkContext.addFile(\"dbfs:/FileStore/tables/cloudkarafka.jaas\")\n\nprintln(\"driver.extra  :\" + spark.conf.get(\"spark.driver.extraJavaOptions\"));\nprintln(\"executor.extra:\" + spark.conf.get(\"spark.executor.extraJavaOptions\"));\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1db50648-04c1-44d3-b718-2fcdf2d491f4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">auth.lang:dbfs:/FileStore/tables/cloudkarafka.jaas\nsasl.jaas:dbfs:/FileStore/tables/cloudkarafka.jaas\ndriver.extra  :-Djava.security.auth.login.config=dbfs:/FileStore/tables/cloudkarafka.jaas\nexecutor.extra:-Djava.io.tmpdir=/local_disk0/tmp -XX:ReservedCodeCacheSize=256m -XX:+UseCodeCacheFlushing -Djava.security.properties=/databricks/spark/dbconf/java/extra.security -XX:-UseContainerSupport -XX:+PrintFlagsFinal -XX:+PrintGCDateStamps -verbose:gc -XX:+PrintGCDetails -Xss4m -Djava.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni -Djavax.xml.datatype.DatatypeFactory=com.sun.org.apache.xerces.internal.jaxp.datatype.DatatypeFactoryImpl -Djavax.xml.parsers.DocumentBuilderFactory=com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl -Djavax.xml.parsers.SAXParserFactory=com.sun.org.apache.xerces.internal.jaxp.SAXParserFactoryImpl -Djavax.xml.validation.SchemaFactory:http://www.w3.org/2001/XMLSchema=com.sun.org.apache.xerces.internal.jaxp.validation.XMLSchemaFactory -Dorg.xml.sax.driver=com.sun.org.apache.xerces.internal.parsers.SAXParser -Dorg.w3c.dom.DOMImplementationSourceList=com.sun.org.apache.xerces.internal.dom.DOMXSImplementationSourceImpl -Djavax.net.ssl.sessionCacheSize=10000 -Dscala.reflect.runtime.disable.typetag.cache=true -Djava.security.auth.login.config=dbfs:/FileStore/tables/cloudkarafka.jaas -Ddatabricks.serviceName=spark-executor-1\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">auth.lang:dbfs:/FileStore/tables/cloudkarafka.jaas\nsasl.jaas:dbfs:/FileStore/tables/cloudkarafka.jaas\ndriver.extra  :-Djava.security.auth.login.config=dbfs:/FileStore/tables/cloudkarafka.jaas\nexecutor.extra:-Djava.io.tmpdir=/local_disk0/tmp -XX:ReservedCodeCacheSize=256m -XX:+UseCodeCacheFlushing -Djava.security.properties=/databricks/spark/dbconf/java/extra.security -XX:-UseContainerSupport -XX:+PrintFlagsFinal -XX:+PrintGCDateStamps -verbose:gc -XX:+PrintGCDetails -Xss4m -Djava.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib:/usr/lib/x86_64-linux-gnu/jni:/lib/x86_64-linux-gnu:/usr/lib/x86_64-linux-gnu:/usr/lib/jni -Djavax.xml.datatype.DatatypeFactory=com.sun.org.apache.xerces.internal.jaxp.datatype.DatatypeFactoryImpl -Djavax.xml.parsers.DocumentBuilderFactory=com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderFactoryImpl -Djavax.xml.parsers.SAXParserFactory=com.sun.org.apache.xerces.internal.jaxp.SAXParserFactoryImpl -Djavax.xml.validation.SchemaFactory:http://www.w3.org/2001/XMLSchema=com.sun.org.apache.xerces.internal.jaxp.validation.XMLSchemaFactory -Dorg.xml.sax.driver=com.sun.org.apache.xerces.internal.parsers.SAXParser -Dorg.w3c.dom.DOMImplementationSourceList=com.sun.org.apache.xerces.internal.dom.DOMXSImplementationSourceImpl -Djavax.net.ssl.sessionCacheSize=10000 -Dscala.reflect.runtime.disable.typetag.cache=true -Djava.security.auth.login.config=dbfs:/FileStore/tables/cloudkarafka.jaas -Ddatabricks.serviceName=spark-executor-1\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql import SparkSession\nfrom pyspark.sql.functions import explode\nfrom pyspark.sql.functions import split\n\nspark = SparkSession \\\n    .builder \\\n    .appName(\"Spark-Karafka-Test\") \\\n    .getOrCreate()\n#https://docs.confluent.io/3.0.0/kafka/sasl.html\n#kafkashaded.org.apache.kafka.common.errors.UnsupportedSaslMechanismException: Client SASL mechanism 'PLAIN' not enabled in the server, enabled mechanisms are [SCRAM-SHA-256]\ndf = spark \\\n    .readStream \\\n    .format(\"kafka\") \\\n    .option(\"kafka.bootstrap.servers\", \"omnibus-01.srvs.cloudkafka.com:9094,omnibus-02.srvs.cloudkafka.com:9094,omnibus-03.srvs.cloudkafka.com:9094\") \\\n    .option(\"kafka.security.protocol\", \"SASL_SSL\") \\\n    .option(\"kafka.sasl.mechanism\", \"SCRAM-SHA-256\") \\\n    .option(\"security.protocol\", \"SASL_SSL\") \\\n    .option(\"sasl.mechanism\", \"SCRAM-SHA-256\") \\\n    .option(\"subscribe\", \"yrmfqh3q-test\") \\\n    .load()\nprint(\"df1:\", df)\n\ndf.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\nprint(\"df2:\", df)\n\nds = df \\\n  .writeStream \\\n  .format(\"kafka\") \\\n  .option(\"kafka.bootstrap.servers\", \"omnibus-01.srvs.cloudkafka.com:9094,omnibus-02.srvs.cloudkafka.com:9094,omnibus-03.srvs.cloudkafka.com:9094\") \\\n  .option(\"kafka.security.protocol\", \"SASL_SSL\") \\\n  .option(\"kafka.sasl.mechanism\", \"SCRAM-SHA-256\") \\\n  .option(\"security.protocol\", \"SASL_SSL\") \\\n  .option(\"sasl.mechanism\", \"SCRAM-SHA-256\") \\\n  .option(\"checkpointLocation\", \"/tmp/stream/pykafka_test/\") \\\n  .option(\"topic\", \"yrmfqh3q-default\") \\\n  .start()\nprint(\"ds:\", ds)\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ec1e5086-8312-403b-9a9e-b76dff4c19ff"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">df1: DataFrame[key: binary, value: binary, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int]\ndf2: DataFrame[key: binary, value: binary, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int]\nds: &lt;pyspark.sql.streaming.StreamingQuery object at 0x7f1bb51f1c50&gt;\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">df1: DataFrame[key: binary, value: binary, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int]\ndf2: DataFrame[key: binary, value: binary, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int]\nds: &lt;pyspark.sql.streaming.StreamingQuery object at 0x7f1bb51f1c50&gt;\n</div>"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"pyspark-karafka-test","dashboards":[],"language":"python","widgets":{},"notebookOrigID":3303468503561633}},"nbformat":4,"nbformat_minor":0}
