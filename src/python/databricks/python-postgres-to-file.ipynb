{"cells":[{"cell_type":"markdown","source":["## Overview\n\nThis notebook shows you how to load data from JDBC databases using Spark SQL.\n\n*For production, you should control the level of parallelism used to read data from the external database, using the parameters described in the documentation.*"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"96816ed7-b08a-4ca3-abb9-f99880c3535d"}}},{"cell_type":"markdown","source":["### Step 1: Connection Information\n\nThis is a **Python** notebook so the default cell type is Python. However, you can use different languages by using the `%LANGUAGE` magic command. Python, Scala, SQL, and R are all supported.\n\nFirst we'll define some variables to let us programmatically create these connections."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"84d079e4-93e8-460d-9d95-54a3fa326ca1"}}},{"cell_type":"code","source":["pip install json5"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6c2dae14-16ee-4147-b1d5-47030a4e45ae"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting json5\n  Downloading json5-0.9.5-py2.py3-none-any.whl (17 kB)\nInstalling collected packages: json5\nSuccessfully installed json5-0.9.5\nPython interpreter will be restarted.\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Python interpreter will be restarted.\nCollecting json5\n  Downloading json5-0.9.5-py2.py3-none-any.whl (17 kB)\nInstalling collected packages: json5\nSuccessfully installed json5-0.9.5\nPython interpreter will be restarted.\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["driver = \"org.postgresql.Driver\"\nurl = \"jdbc:postgresql://queenie.db.elephantsql.com:5432/ycfglres\"\nuser = \"ycfglres\"\npassword = \"z-PQKACVeHQ_f6wbuQQPpmyDJ55IhNwN\""],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6482be4c-f067-47c9-b0ac-35c938b94601"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Step 2: Reading the data\n\nNow that we specified our file metadata, we can create a DataFrame. You'll notice that we use an *option* to specify that we'd like to infer the schema from the file. We can also explicitly set this to a particular schema if we have one already.\n\nFirst, let's create a DataFrame in Python, notice how we will programmatically reference the variables we defined above."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"51114086-25f5-4c9c-8bb3-64ff28b0f0f4"}}},{"cell_type":"code","source":["import json5 as json\n\nprint(\"============== ITEMS FROM POSTGRES ==============\")\ntable = \"item\"\ndf_items = spark.read.format(\"jdbc\")\\\n  .option(\"driver\", driver)\\\n  .option(\"url\", url)\\\n  .option(\"dbtable\", table)\\\n  .option(\"user\", user)\\\n  .option(\"password\", password)\\\n  .load()\n\nprint(\"df_items\")\ndf_items.show()\n#df_items.toJSON().collect(): ['{\"Id\":1,\"Name\":\"Bananas\",\"Desc\":\"Bananas\",\"Active\":\"1\"}']\nitems = []\nfor e in df_items.toJSON().collect():\n  e = json.loads(e)\n  items.append(e)\nprint(\"Items as JSON Array\", items)\nbc_items = spark.sparkContext.broadcast(items)\n\n\nprint(\"============== STORE FROM POSTGRES ==============\")\ntable = \"store\"\ndf_store = spark.read.format(\"jdbc\")\\\n  .option(\"driver\", driver)\\\n  .option(\"url\", url)\\\n  .option(\"dbtable\", table)\\\n  .option(\"user\", user)\\\n  .option(\"password\", password)\\\n  .load()\n\nprint(\"df_store\")\ndf_store.show()\nstores = []\n#['{\"Id\":1,\"Name\":\"Store-A\",\"City\":\"New York\",\"State\":\"New York\",\"Country\":\"USA\",\"Active\":1}']\nfor e in df_store.toJSON().collect():\n  e = json.loads(e)\n  stores.append(e)\nprint(\"Stores as JSON Array\", stores)\nbc_stores = spark.sparkContext.broadcast(stores)\n\n\nprint(\"============== TRANSACTIONS FROM POSTGRES ==============\")\ntable = \"transaction\"\ndf_trans = spark.read.format(\"jdbc\")\\\n  .option(\"driver\", driver)\\\n  .option(\"url\", url)\\\n  .option(\"dbtable\", table)\\\n  .option(\"user\", user)\\\n  .option(\"password\", password)\\\n  .load()\nprint(\"df_trans\")\ndf_trans.show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f6366891-7da1-478e-8094-4291f4fca976"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">============== ITEMS FROM POSTGRES ==============\ndf_items\n+---+-------+-------------+------+\n| Id|   Name|         Desc|Active|\n+---+-------+-------------+------+\n|  1|Bananas|      Bananas|     1|\n|  2| Apples|  Gala Apples|     1|\n|  3|Organes|Naval Oranges|     1|\n+---+-------+-------------+------+\n\nItems as JSON Array [{&#39;Id&#39;: 1, &#39;Name&#39;: &#39;Bananas&#39;, &#39;Desc&#39;: &#39;Bananas&#39;, &#39;Active&#39;: &#39;1&#39;}, {&#39;Id&#39;: 2, &#39;Name&#39;: &#39;Apples&#39;, &#39;Desc&#39;: &#39;Gala Apples&#39;, &#39;Active&#39;: &#39;1&#39;}, {&#39;Id&#39;: 3, &#39;Name&#39;: &#39;Organes&#39;, &#39;Desc&#39;: &#39;Naval Oranges&#39;, &#39;Active&#39;: &#39;1&#39;}]\n============== STORE FROM POSTGRES ==============\ndf_store\n+---+-------+----------+--------+-------+------+\n| Id|   Name|      City|   State|Country|Active|\n+---+-------+----------+--------+-------+------+\n|  1|Store-A|  New York|New York|    USA|     1|\n|  2|Store-B|Washington| Seattle|    USA|     1|\n|  3|Store-C|    Dallas|   Texas|    USA|     1|\n+---+-------+----------+--------+-------+------+\n\nStores as JSON Array [{&#39;Id&#39;: 1, &#39;Name&#39;: &#39;Store-A&#39;, &#39;City&#39;: &#39;New York&#39;, &#39;State&#39;: &#39;New York&#39;, &#39;Country&#39;: &#39;USA&#39;, &#39;Active&#39;: &#39;1&#39;}, {&#39;Id&#39;: 2, &#39;Name&#39;: &#39;Store-B&#39;, &#39;City&#39;: &#39;Washington&#39;, &#39;State&#39;: &#39;Seattle&#39;, &#39;Country&#39;: &#39;USA&#39;, &#39;Active&#39;: &#39;1&#39;}, {&#39;Id&#39;: 3, &#39;Name&#39;: &#39;Store-C&#39;, &#39;City&#39;: &#39;Dallas&#39;, &#39;State&#39;: &#39;Texas&#39;, &#39;Country&#39;: &#39;USA&#39;, &#39;Active&#39;: &#39;1&#39;}]\n============== TRANSACTIONS FROM POSTGRES ==============\ndf_trans\n+---+-------+------+--------------------+----------+\n|TId|StoreId|ItemId|               TDesc|     TDate|\n+---+-------+------+--------------------+----------+\n|  1|      1|     2|Apples for StoreB...|2021-04-19|\n|  2|      3|     3|Oranges for Store...|2021-04-18|\n|  3|      2|     1|Bananas for Store...|2021-04-17|\n+---+-------+------+--------------------+----------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">============== ITEMS FROM POSTGRES ==============\ndf_items\n+---+-------+-------------+------+\n Id|   Name|         Desc|Active|\n+---+-------+-------------+------+\n  1|Bananas|      Bananas|     1|\n  2| Apples|  Gala Apples|     1|\n  3|Organes|Naval Oranges|     1|\n+---+-------+-------------+------+\n\nItems as JSON Array [{&#39;Id&#39;: 1, &#39;Name&#39;: &#39;Bananas&#39;, &#39;Desc&#39;: &#39;Bananas&#39;, &#39;Active&#39;: &#39;1&#39;}, {&#39;Id&#39;: 2, &#39;Name&#39;: &#39;Apples&#39;, &#39;Desc&#39;: &#39;Gala Apples&#39;, &#39;Active&#39;: &#39;1&#39;}, {&#39;Id&#39;: 3, &#39;Name&#39;: &#39;Organes&#39;, &#39;Desc&#39;: &#39;Naval Oranges&#39;, &#39;Active&#39;: &#39;1&#39;}]\n============== STORE FROM POSTGRES ==============\ndf_store\n+---+-------+----------+--------+-------+------+\n Id|   Name|      City|   State|Country|Active|\n+---+-------+----------+--------+-------+------+\n  1|Store-A|  New York|New York|    USA|     1|\n  2|Store-B|Washington| Seattle|    USA|     1|\n  3|Store-C|    Dallas|   Texas|    USA|     1|\n+---+-------+----------+--------+-------+------+\n\nStores as JSON Array [{&#39;Id&#39;: 1, &#39;Name&#39;: &#39;Store-A&#39;, &#39;City&#39;: &#39;New York&#39;, &#39;State&#39;: &#39;New York&#39;, &#39;Country&#39;: &#39;USA&#39;, &#39;Active&#39;: &#39;1&#39;}, {&#39;Id&#39;: 2, &#39;Name&#39;: &#39;Store-B&#39;, &#39;City&#39;: &#39;Washington&#39;, &#39;State&#39;: &#39;Seattle&#39;, &#39;Country&#39;: &#39;USA&#39;, &#39;Active&#39;: &#39;1&#39;}, {&#39;Id&#39;: 3, &#39;Name&#39;: &#39;Store-C&#39;, &#39;City&#39;: &#39;Dallas&#39;, &#39;State&#39;: &#39;Texas&#39;, &#39;Country&#39;: &#39;USA&#39;, &#39;Active&#39;: &#39;1&#39;}]\n============== TRANSACTIONS FROM POSTGRES ==============\ndf_trans\n+---+-------+------+--------------------+----------+\nTId|StoreId|ItemId|               TDesc|     TDate|\n+---+-------+------+--------------------+----------+\n  1|      1|     2|Apples for StoreB...|2021-04-19|\n  2|      3|     3|Oranges for Store...|2021-04-18|\n  3|      2|     1|Bananas for Store...|2021-04-17|\n+---+-------+------+--------------------+----------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Step 3: Querying the data\n\nNow that we created our DataFrame. We can query it. For instance, you can select some particular columns to select and display within Databricks."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"92108b48-e8f5-4d0d-9d24-3775b36ca207"}}},{"cell_type":"code","source":["display(df_items.select(\"Name\"))\ndisplay(df_store.select(\"Name\"))\ndisplay(df_trans.select(\"TDesc\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fec0eb47-1220-48a6-81b4-adb261a7265a"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["print(\"===================== MAP =====================\")\nimport json5 as json\nimport pyspark.sql.functions as f\nimport pyspark\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.functions import col,sum,avg\nfrom pyspark.sql.types import Row\nimport json5 as json\n\ndef myTransEnrich(row, bc_stores, bc_items):\n  print(\"myTransEnrich::type:%s, data:%s\" % (type(row), row))\n  #myTransEnrich::type:<class 'pyspark.sql.types.Row'>, data:Row(TId=1, StoreId=3, ItemId=3, TDesc='Oranges for StoreC@DAL', TDate='2021-04-19T02:01:01')\n  row_dict = row.asDict()\n  print(\"myTransEnrich::row_dict:\", type(row_dict), row_dict)\n  #myTransEnrich::row_dict: <class 'dict'> {'TId': 1, 'StoreId': 2, 'ItemId': 1, 'TDesc': 'Bananas for StoreA@NYC', 'TDate': '2021-04-19T03:01:01'}\n  itemId = row_dict.get(\"ItemId\")\n  storeId = row_dict.get(\"StoreId\")\n        \n  #print(\"myTransEnrich::bc_user.value::\", type(bc_stores.value), bc_stores.value)\n  #myTransEnrich::bc_user.value:: <class 'list'> [{'Id': 1, 'Name': 'Store-A', 'City': 'New York', 'State': 'New York', 'Country': 'USA', 'Active': 1}]\n  myitem = list(filter(lambda x:x[\"Id\"]==storeId, bc_stores.value))\n  print(\"myTransEnrich::myitem:\", (myitem))\n  #myTransEnrich::myitem: [{'Id': 3, 'Name': 'Store-C', 'City': 'Dallas', 'State': 'Texas', 'Country': 'USA', 'Active': 1}]\n  myitem = myitem[0]\n  row_dict[\"ItemName\"] = myitem[\"Name\"]\n\n  #print(\"myTransEnrich::bc_items.value::\", type(bc_items.value), bc_items.value)\n  #myTransEnrich::bc_items.value:: <class 'list'> [{'Id': 1, 'Name': 'Bananas', 'Desc': 'Bananas', 'Active': '1'}]\n  mystore = list(filter(lambda x:x[\"Id\"]==itemId, bc_items.value))\n  print(\"myTransEnrich::mystore:\", (mystore))\n  #myTransEnrich::mystore: [{'Id': 3, 'Name': 'Organes', 'Desc': 'Naval Oranges', 'Active': '1'}]\n  mystore = mystore[0]\n  row_dict[\"StoreName\"] = mystore[\"Name\"]\n  \n  return Row(**row_dict)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"87fe80ca-1d4c-48c7-b8df-863292228f98"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">===================== MAP =====================\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">===================== MAP =====================\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["df_enriched = df_trans.rdd.map(lambda row: myTransEnrich(row, bc_stores, bc_items))\nprint(\"df_enriched:0:\", df_enriched)\ndf_enriched.toDF([\"TId\", \"StoreId\", \"ItemId\", \"TDesc\", \"TDate\"]).show()\n\n#remote_table.write.format(\"parquet\").saveAsTable(\"MY_PERMANENT_TABLE_NAME\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"db9631f6-bb4a-42ca-8a3c-0d48af932331"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">df_enriched:0: PythonRDD[98] at RDD at PythonRDD.scala:58\n+---+-------+------+--------------------+----------+--------+---------+\n|TId|StoreId|ItemId|               TDesc|     TDate|ItemName|StoreName|\n+---+-------+------+--------------------+----------+--------+---------+\n|  1|      1|     2|Apples for StoreB...|2021-04-19| Store-A|   Apples|\n|  2|      3|     3|Oranges for Store...|2021-04-18| Store-C|  Organes|\n|  3|      2|     1|Bananas for Store...|2021-04-17| Store-B|  Bananas|\n+---+-------+------+--------------------+----------+--------+---------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">df_enriched:0: PythonRDD[98] at RDD at PythonRDD.scala:58\n+---+-------+------+--------------------+----------+--------+---------+\nTId|StoreId|ItemId|               TDesc|     TDate|ItemName|StoreName|\n+---+-------+------+--------------------+----------+--------+---------+\n  1|      1|     2|Apples for StoreB...|2021-04-19| Store-A|   Apples|\n  2|      3|     3|Oranges for Store...|2021-04-18| Store-C|  Organes|\n  3|      2|     1|Bananas for Store...|2021-04-17| Store-B|  Bananas|\n+---+-------+------+--------------------+----------+--------+---------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["This table will persist across cluster restarts as well as allow various users across different notebooks to query this data. However, this will not connect back to the original database when doing so."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0880bffd-4f8d-4565-8428-ace92f92a53c"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"python-postgres-to-file","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":1472450366695382}},"nbformat":4,"nbformat_minor":0}
